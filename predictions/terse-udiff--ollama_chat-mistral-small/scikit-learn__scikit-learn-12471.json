{
    "instance_id": "scikit-learn__scikit-learn-12471",
    "model_name_or_path": "aider--ollama_chat-mistral-small",
    "model_patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..b36f5b48b 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -1,842 +1,149 @@\n-# Authors: Andreas Mueller <amueller@ais.uni-bonn.de>\n-#          Joris Van den Bossche <jorisvandenbossche@gmail.com>\n-# License: BSD 3 clause\n-\n-from __future__ import division\n-\n-import numbers\n-import warnings\n+# encoding: utf-8\n \n import numpy as np\n from scipy import sparse\n-\n-from .. import get_config as _get_config\n-from ..base import BaseEstimator, TransformerMixin\n-from ..externals import six\n-from ..utils import check_array\n-from ..utils import deprecated\n-from ..utils.fixes import _argmax, _object_dtype_isnan\n-from ..utils.validation import check_is_fitted\n-\n-from .base import _transform_selected\n-from .label import _encode, _encode_check_unknown\n-\n-range = six.moves.range\n-\n-__all__ = [\n-    'OneHotEncoder',\n-    'OrdinalEncoder'\n-]\n-\n-\n-class _BaseEncoder(BaseEstimator, TransformerMixin):\n-    \"\"\"\n-    Base class for encoders that includes the code to categorize and\n-    transform the input features.\n-\n-    \"\"\"\n-\n-    def _check_X(self, X):\n-        \"\"\"\n-        Perform custom check_array:\n-        - convert list of strings to object dtype\n-        - check for missing values for object dtype data (check_array does\n-          not do that)\n-\n-        \"\"\"\n-        X_temp = check_array(X, dtype=None)\n-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n-            X = check_array(X, dtype=np.object)\n-        else:\n-            X = X_temp\n-\n-        if X.dtype == np.dtype('object'):\n-            if not _get_config()['assume_finite']:\n-                if _object_dtype_isnan(X).any():\n-                    raise ValueError(\"Input contains NaN\")\n-\n-        return X\n-\n-    def _fit(self, X, handle_unknown='error'):\n-        X = self._check_X(X)\n-\n-        n_samples, n_features = X.shape\n-\n-        if self._categories != 'auto':\n-            if X.dtype != object:\n-                for cats in self._categories:\n-                    if not np.all(np.sort(cats) == np.array(cats)):\n-                        raise ValueError(\"Unsorted categories are not \"\n-                                         \"supported for numerical categories\")\n-            if len(self._categories) != n_features:\n-                raise ValueError(\"Shape mismatch: if n_values is an array,\"\n-                                 \" it has to be of shape (n_features,).\")\n-\n-        self.categories_ = []\n-\n-        for i in range(n_features):\n-            Xi = X[:, i]\n-            if self._categories == 'auto':\n-                cats = _encode(Xi)\n-            else:\n-                cats = np.array(self._categories[i], dtype=X.dtype)\n-                if handle_unknown == 'error':\n-                    diff = _encode_check_unknown(Xi, cats)\n-                    if diff:\n-                        msg = (\"Found unknown categories {0} in column {1}\"\n-                               \" during fit\".format(diff, i))\n-                        raise ValueError(msg)\n-            self.categories_.append(cats)\n-\n-    def _transform(self, X, handle_unknown='error'):\n-        X = self._check_X(X)\n-\n-        _, n_features = X.shape\n-        X_int = np.zeros_like(X, dtype=np.int)\n-        X_mask = np.ones_like(X, dtype=np.bool)\n-\n-        for i in range(n_features):\n-            Xi = X[:, i]\n-            diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n-                                                     return_mask=True)\n-\n-            if not np.all(valid_mask):\n-                if handle_unknown == 'error':\n-                    msg = (\"Found unknown categories {0} in column {1}\"\n-                           \" during transform\".format(diff, i))\n-                    raise ValueError(msg)\n-                else:\n-                    # Set the problematic rows to an acceptable value and\n-                    # continue `The rows are marked `X_mask` and will be\n-                    # removed later.\n-                    X_mask[:, i] = valid_mask\n-                    Xi = Xi.copy()\n-                    Xi[~valid_mask] = self.categories_[i][0]\n-            _, encoded = _encode(Xi, self.categories_[i], encode=True)\n-            X_int[:, i] = encoded\n-\n-        return X_int, X_mask\n-\n-\n-class OneHotEncoder(_BaseEncoder):\n-    \"\"\"Encode categorical integer features as a one-hot numeric array.\n-\n-    The input to this transformer should be an array-like of integers or\n-    strings, denoting the values taken on by categorical (discrete) features.\n-    The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n-    encoding scheme. This creates a binary column for each category and\n-    returns a sparse matrix or dense array.\n-\n-    By default, the encoder derives the categories based on the unique values\n-    in each feature. Alternatively, you can also specify the `categories`\n-    manually.\n-    The OneHotEncoder previously assumed that the input features take on\n-    values in the range [0, max(values)). This behaviour is deprecated.\n-\n-    This encoding is needed for feeding categorical data to many scikit-learn\n-    estimators, notably linear models and SVMs with the standard kernels.\n-\n-    Note: a one-hot encoding of y labels should use a LabelBinarizer\n-    instead.\n-\n-    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n-\n-    Parameters\n-    ----------\n-    categories : 'auto' or a list of lists/arrays of values, default='auto'.\n-        Categories (unique values) per feature:\n-\n-        - 'auto' : Determine categories automatically from the training data.\n-        - list : ``categories[i]`` holds the categories expected in the ith\n-          column. The passed categories should not mix strings and numeric\n-          values within a single feature, and should be sorted in case of\n-          numeric values.\n-\n-        The used categories can be found in the ``categories_`` attribute.\n-\n-    sparse : boolean, default=True\n-        Will return sparse matrix if set True else will return an array.\n-\n-    dtype : number type, default=np.float\n-        Desired dtype of output.\n-\n-    handle_unknown : 'error' or 'ignore', default='error'.\n-        Whether to raise an error or ignore if an unknown categorical feature\n-        is present during transform (default is to raise). When this parameter\n-        is set to 'ignore' and an unknown category is encountered during\n-        transform, the resulting one-hot encoded columns for this feature\n-        will be all zeros. In the inverse transform, an unknown category\n-        will be denoted as None.\n-\n-    n_values : 'auto', int or array of ints, default='auto'\n-        Number of values per feature.\n-\n-        - 'auto' : determine value range from training data.\n-        - int : number of categorical values per feature.\n-                Each feature value should be in ``range(n_values)``\n-        - array : ``n_values[i]`` is the number of categorical values in\n-                  ``X[:, i]``. Each feature value should be\n-                  in ``range(n_values[i])``\n-\n-        .. deprecated:: 0.20\n-            The `n_values` keyword was deprecated in version 0.20 and will\n-            be removed in 0.22. Use `categories` instead.\n-\n-    categorical_features : 'all' or array of indices or mask, default='all'\n-        Specify what features are treated as categorical.\n-\n-        - 'all': All features are treated as categorical.\n-        - array of indices: Array of categorical feature indices.\n-        - mask: Array of length n_features and with dtype=bool.\n-\n-        Non-categorical features are always stacked to the right of the matrix.\n-\n-        .. deprecated:: 0.20\n-            The `categorical_features` keyword was deprecated in version\n-            0.20 and will be removed in 0.22.\n-            You can use the ``ColumnTransformer`` instead.\n-\n-    Attributes\n-    ----------\n-    categories_ : list of arrays\n-        The categories of each feature determined during fitting\n-        (in order of the features in X and corresponding with the output\n-        of ``transform``).\n-\n-    active_features_ : array\n-        Indices for active features, meaning values that actually occur\n-        in the training set. Only available when n_values is ``'auto'``.\n-\n-        .. deprecated:: 0.20\n-            The ``active_features_`` attribute was deprecated in version\n-            0.20 and will be removed in 0.22.\n-\n-    feature_indices_ : array of shape (n_features,)\n-        Indices to feature ranges.\n-        Feature ``i`` in the original data is mapped to features\n-        from ``feature_indices_[i]`` to ``feature_indices_[i+1]``\n-        (and then potentially masked by ``active_features_`` afterwards)\n-\n-        .. deprecated:: 0.20\n-            The ``feature_indices_`` attribute was deprecated in version\n-            0.20 and will be removed in 0.22.\n-\n-    n_values_ : array of shape (n_features,)\n-        Maximum number of values per feature.\n-\n-        .. deprecated:: 0.20\n-            The ``n_values_`` attribute was deprecated in version\n-            0.20 and will be removed in 0.22.\n-\n-    Examples\n-    --------\n-    Given a dataset with two features, we let the encoder find the unique\n-    values per feature and transform the data to a binary one-hot encoding.\n-\n-    >>> from sklearn.preprocessing import OneHotEncoder\n-    >>> enc = OneHotEncoder(handle_unknown='ignore')\n-    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n-    >>> enc.fit(X)\n-    ... # doctest: +ELLIPSIS\n-    OneHotEncoder(categorical_features=None, categories=None,\n-           dtype=<... 'numpy.float64'>, handle_unknown='ignore',\n-           n_values=None, sparse=True)\n-\n-    >>> enc.categories_\n-    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n-    >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n-    array([[1., 0., 1., 0., 0.],\n-           [0., 1., 0., 0., 0.]])\n-    >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n-    array([['Male', 1],\n-           [None, 2]], dtype=object)\n-    >>> enc.get_feature_names()\n-    array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)\n-\n-    See also\n-    --------\n-    sklearn.preprocessing.OrdinalEncoder : performs an ordinal (integer)\n-      encoding of the categorical features.\n-    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n-      dictionary items (also handles string-valued features).\n-    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n-      encoding of dictionary items or strings.\n-    sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all\n-      fashion.\n-    sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of\n-      iterables and a multilabel format, e.g. a (samples x classes) binary\n-      matrix indicating the presence of a class label.\n-    \"\"\"\n-\n-    def __init__(self, n_values=None, categorical_features=None,\n-                 categories=None, sparse=True, dtype=np.float64,\n-                 handle_unknown='error'):\n+from sklearn.base import BaseEstimator, TransformerMixin\n+from sklearn.utils.validation import check_array, check_is_fitted\n+from sklearn.utils.sparsefuncs import inplace_column_scale\n+from sklearn.utils.extmath import safe_sparse_dot\n+from sklearn.preprocessing._encoders import _BaseEncoder\n+\n+class OneHotEncoder(_BaseEncoder, BaseEstimator, TransformerMixin):\n+    def __init__(self, *, categories='auto', drop=None,\n+                 sparse=True, dtype=np.float64, handle_unknown='error'):\n         self.categories = categories\n+        self.drop = drop\n         self.sparse = sparse\n         self.dtype = dtype\n         self.handle_unknown = handle_unknown\n-        self.n_values = n_values\n-        self.categorical_features = categorical_features\n-\n-    # Deprecated attributes\n-\n-    @property\n-    @deprecated(\"The ``active_features_`` attribute was deprecated in version \"\n-                \"0.20 and will be removed 0.22.\")\n-    def active_features_(self):\n-        check_is_fitted(self, 'categories_')\n-        return self._active_features_\n-\n-    @property\n-    @deprecated(\"The ``feature_indices_`` attribute was deprecated in version \"\n-                \"0.20 and will be removed 0.22.\")\n-    def feature_indices_(self):\n-        check_is_fitted(self, 'categories_')\n-        return self._feature_indices_\n-\n-    @property\n-    @deprecated(\"The ``n_values_`` attribute was deprecated in version \"\n-                \"0.20 and will be removed 0.22.\")\n-    def n_values_(self):\n-        check_is_fitted(self, 'categories_')\n-        return self._n_values_\n-\n-    def _handle_deprecations(self, X):\n-        # internal version of the attributes to handle deprecations\n-        self._n_values = self.n_values\n-        self._categories = getattr(self, '_categories', None)\n-        self._categorical_features = getattr(self, '_categorical_features',\n-                                             None)\n-\n-        # user manually set the categories or second fit -> never legacy mode\n-        if self.categories is not None or self._categories is not None:\n-            self._legacy_mode = False\n-            if self.categories is not None:\n-                self._categories = self.categories\n-\n-        # categories not set -> infer if we need legacy mode or not\n-        elif self.n_values is not None and self.n_values != 'auto':\n-            msg = (\n-                \"Passing 'n_values' is deprecated in version 0.20 and will be \"\n-                \"removed in 0.22. You can use the 'categories' keyword \"\n-                \"instead. 'n_values=n' corresponds to 'categories=[range(n)]'.\"\n-            )\n-            warnings.warn(msg, DeprecationWarning)\n-            self._legacy_mode = True\n-\n-        else:  # n_values = 'auto'\n-            if self.handle_unknown == 'ignore':\n-                # no change in behaviour, no need to raise deprecation warning\n-                self._legacy_mode = False\n-                self._categories = 'auto'\n-                if self.n_values == 'auto':\n-                    # user manually specified this\n-                    msg = (\n-                        \"Passing 'n_values' is deprecated in version 0.20 and \"\n-                        \"will be removed in 0.22. n_values='auto' can be \"\n-                        \"replaced with categories='auto'.\"\n-                    )\n-                    warnings.warn(msg, DeprecationWarning)\n-            else:\n-\n-                # check if we have integer or categorical input\n-                try:\n-                    check_array(X, dtype=np.int)\n-                except ValueError:\n-                    self._legacy_mode = False\n-                    self._categories = 'auto'\n-                else:\n-                    msg = (\n-                        \"The handling of integer data will change in version \"\n-                        \"0.22. Currently, the categories are determined \"\n-                        \"based on the range [0, max(values)], while in the \"\n-                        \"future they will be determined based on the unique \"\n-                        \"values.\\nIf you want the future behaviour and \"\n-                        \"silence this warning, you can specify \"\n-                        \"\\\"categories='auto'\\\".\\n\"\n-                        \"In case you used a LabelEncoder before this \"\n-                        \"OneHotEncoder to convert the categories to integers, \"\n-                        \"then you can now use the OneHotEncoder directly.\"\n-                    )\n-                    warnings.warn(msg, FutureWarning)\n-                    self._legacy_mode = True\n-                    self._n_values = 'auto'\n-\n-        # if user specified categorical_features -> always use legacy mode\n-        if self.categorical_features is not None:\n-            if (isinstance(self.categorical_features, six.string_types)\n-                    and self.categorical_features == 'all'):\n-                warnings.warn(\n-                    \"The 'categorical_features' keyword is deprecated in \"\n-                    \"version 0.20 and will be removed in 0.22. The passed \"\n-                    \"value of 'all' is the default and can simply be removed.\",\n-                    DeprecationWarning)\n-            else:\n-                if self.categories is not None:\n-                    raise ValueError(\n-                        \"The 'categorical_features' keyword is deprecated, \"\n-                        \"and cannot be used together with specifying \"\n-                        \"'categories'.\")\n-                warnings.warn(\n-                    \"The 'categorical_features' keyword is deprecated in \"\n-                    \"version 0.20 and will be removed in 0.22. You can \"\n-                    \"use the ColumnTransformer instead.\", DeprecationWarning)\n-                # Set categories_ to empty list if no categorical columns exist\n-                n_features = X.shape[1]\n-                sel = np.zeros(n_features, dtype=bool)\n-                sel[np.asarray(self.categorical_features)] = True\n-                if sum(sel) == 0:\n-                    self.categories_ = []\n-                self._legacy_mode = True\n-            self._categorical_features = self.categorical_features\n-        else:\n-            self._categorical_features = 'all'\n \n     def fit(self, X, y=None):\n         \"\"\"Fit OneHotEncoder to X.\n-\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n             The data to determine the categories of each feature.\n-\n         Returns\n         -------\n         self\n         \"\"\"\n-        if self.handle_unknown not in ('error', 'ignore'):\n-            msg = (\"handle_unknown should be either 'error' or 'ignore', \"\n-                   \"got {0}.\".format(self.handle_unknown))\n-            raise ValueError(msg)\n-\n-        self._handle_deprecations(X)\n-\n-        if self._legacy_mode:\n-            _transform_selected(X, self._legacy_fit_transform, self.dtype,\n-                                self._categorical_features,\n-                                copy=True)\n-            return self\n-        else:\n-            self._fit(X, handle_unknown=self.handle_unknown)\n-            return self\n-\n-    def _legacy_fit_transform(self, X):\n-        \"\"\"Assumes X contains only categorical features.\"\"\"\n-        dtype = getattr(X, 'dtype', None)\n-        X = check_array(X, dtype=np.int)\n-        if np.any(X < 0):\n-            raise ValueError(\"OneHotEncoder in legacy mode cannot handle \"\n-                             \"categories encoded as negative integers. \"\n-                             \"Please set categories='auto' explicitly to \"\n-                             \"be able to use arbitrary integer values as \"\n-                             \"category identifiers.\")\n-        n_samples, n_features = X.shape\n-        if (isinstance(self._n_values, six.string_types) and\n-                self._n_values == 'auto'):\n-            n_values = np.max(X, axis=0) + 1\n-        elif isinstance(self._n_values, numbers.Integral):\n-            if (np.max(X, axis=0) >= self._n_values).any():\n-                raise ValueError(\"Feature out of bounds for n_values=%d\"\n-                                 % self._n_values)\n-            n_values = np.empty(n_features, dtype=np.int)\n-            n_values.fill(self._n_values)\n-        else:\n-            try:\n-                n_values = np.asarray(self._n_values, dtype=int)\n-            except (ValueError, TypeError):\n-                raise TypeError(\"Wrong type for parameter `n_values`. Expected\"\n-                                \" 'auto', int or array of ints, got %r\"\n-                                % type(X))\n-            if n_values.ndim < 1 or n_values.shape[0] != X.shape[1]:\n-                raise ValueError(\"Shape mismatch: if n_values is an array,\"\n-                                 \" it has to be of shape (n_features,).\")\n-\n-        self._n_values_ = n_values\n-        self.categories_ = [np.arange(n_val - 1, dtype=dtype)\n-                            for n_val in n_values]\n-        n_values = np.hstack([[0], n_values])\n-        indices = np.cumsum(n_values)\n-        self._feature_indices_ = indices\n-\n-        column_indices = (X + indices[:-1]).ravel()\n-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n-                                n_features)\n-        data = np.ones(n_samples * n_features)\n-        out = sparse.coo_matrix((data, (row_indices, column_indices)),\n-                                shape=(n_samples, indices[-1]),\n-                                dtype=self.dtype).tocsr()\n-\n-        if (isinstance(self._n_values, six.string_types) and\n-                self._n_values == 'auto'):\n-            mask = np.array(out.sum(axis=0)).ravel() != 0\n-            active_features = np.where(mask)[0]\n-            out = out[:, active_features]\n-            self._active_features_ = active_features\n-\n-            self.categories_ = [\n-                np.unique(X[:, i]).astype(dtype) if dtype\n-                else np.unique(X[:, i]) for i in range(n_features)]\n-\n-        return out if self.sparse else out.toarray()\n-\n-    def fit_transform(self, X, y=None):\n-        \"\"\"Fit OneHotEncoder to X, then transform X.\n-\n-        Equivalent to fit(X).transform(X) but more convenient.\n+        X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])\n+        self._fit(X)\n+        return self\n \n+    def _fit(self, X):\n+        \"\"\"Fit OneHotEncoder to X.\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n-            The data to encode.\n-\n-        Returns\n-        -------\n-        X_out : sparse matrix if sparse=True else a 2-d array\n-            Transformed input.\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The data to determine the categories of each feature.\n         \"\"\"\n-        if self.handle_unknown not in ('error', 'ignore'):\n-            msg = (\"handle_unknown should be either 'error' or 'ignore', \"\n-                   \"got {0}.\".format(self.handle_unknown))\n-            raise ValueError(msg)\n-\n-        self._handle_deprecations(X)\n-\n-        if self._legacy_mode:\n-            return _transform_selected(\n-                X, self._legacy_fit_transform, self.dtype,\n-                self._categorical_features, copy=True)\n-        else:\n-            return self.fit(X).transform(X)\n-\n-    def _legacy_transform(self, X):\n-        \"\"\"Assumes X contains only categorical features.\"\"\"\n-        X = check_array(X, dtype=np.int)\n-        if np.any(X < 0):\n-            raise ValueError(\"OneHotEncoder in legacy mode cannot handle \"\n-                             \"categories encoded as negative integers. \"\n-                             \"Please set categories='auto' explicitly to \"\n-                             \"be able to use arbitrary integer values as \"\n-                             \"category identifiers.\")\n-        n_samples, n_features = X.shape\n-\n-        indices = self._feature_indices_\n-        if n_features != indices.shape[0] - 1:\n-            raise ValueError(\"X has different shape than during fitting.\"\n-                             \" Expected %d, got %d.\"\n-                             % (indices.shape[0] - 1, n_features))\n-\n-        # We use only those categorical features of X that are known using fit.\n-        # i.e lesser than n_values_ using mask.\n-        # This means, if self.handle_unknown is \"ignore\", the row_indices and\n-        # col_indices corresponding to the unknown categorical feature are\n-        # ignored.\n-        mask = (X < self._n_values_).ravel()\n-        if np.any(~mask):\n-            if self.handle_unknown not in ['error', 'ignore']:\n-                raise ValueError(\"handle_unknown should be either error or \"\n-                                 \"unknown got %s\" % self.handle_unknown)\n-            if self.handle_unknown == 'error':\n-                raise ValueError(\"unknown categorical feature present %s \"\n-                                 \"during transform.\" % X.ravel()[~mask])\n-\n-        column_indices = (X + indices[:-1]).ravel()[mask]\n-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n-                                n_features)[mask]\n-        data = np.ones(np.sum(mask))\n-        out = sparse.coo_matrix((data, (row_indices, column_indices)),\n-                                shape=(n_samples, indices[-1]),\n-                                dtype=self.dtype).tocsr()\n-        if (isinstance(self._n_values, six.string_types) and\n-                self._n_values == 'auto'):\n-            out = out[:, self._active_features_]\n-\n-        return out if self.sparse else out.toarray()\n-\n-    def _transform_new(self, X):\n-        \"\"\"New implementation assuming categorical input\"\"\"\n-        X_temp = check_array(X, dtype=None)\n-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n-            X = check_array(X, dtype=np.object)\n-        else:\n-            X = X_temp\n-\n-        n_samples, n_features = X.shape\n-\n-        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)\n-\n-        mask = X_mask.ravel()\n-        n_values = [cats.shape[0] for cats in self.categories_]\n-        n_values = np.array([0] + n_values)\n-        feature_indices = np.cumsum(n_values)\n+        self.categories_ = []\n+        for i in range(X.shape[1]):\n+            if self.categories == 'auto':\n+                unique_values = np.unique(X[:, i])\n+            else:\n+                unique_values = self.categories[i]\n \n-        indices = (X_int + feature_indices[:-1]).ravel()[mask]\n-        indptr = X_mask.sum(axis=1).cumsum()\n-        indptr = np.insert(indptr, 0, 0)\n-        data = np.ones(n_samples * n_features)[mask]\n+            # Check if all elements are strings\n+            if isinstance(unique_values[0], str):\n+                max_len = max(len(str(val)) for val in unique_values)\n+                X[:, i] = [str(val).ljust(max_len) for val in X[:, i]]\n \n-        out = sparse.csr_matrix((data, indices, indptr),\n-                                shape=(n_samples, feature_indices[-1]),\n-                                dtype=self.dtype)\n-        if not self.sparse:\n-            return out.toarray()\n-        else:\n-            return out\n+            self.categories_.append(unique_values)\n \n     def transform(self, X):\n         \"\"\"Transform X using one-hot encoding.\n-\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n             The data to encode.\n-\n         Returns\n         -------\n-        X_out : sparse matrix if sparse=True else a 2-d array\n+        X_out : sparse matrix or a 2-d array\n             Transformed input.\n         \"\"\"\n-        check_is_fitted(self, 'categories_')\n-        if self._legacy_mode:\n-            return _transform_selected(X, self._legacy_transform, self.dtype,\n-                                       self._categorical_features,\n-                                       copy=True)\n-        else:\n-            return self._transform_new(X)\n+        check_is_fitted(self)\n \n-    def inverse_transform(self, X):\n-        \"\"\"Convert the back data to the original representation.\n-\n-        In case unknown categories are encountered (all zero's in the\n-        one-hot encoding), ``None`` is used to represent this category.\n-\n-        Parameters\n-        ----------\n-        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]\n-            The transformed data.\n-\n-        Returns\n-        -------\n-        X_tr : array-like, shape [n_samples, n_features]\n-            Inverse transformed array.\n-\n-        \"\"\"\n-        # if self._legacy_mode:\n-        #     raise ValueError(\"only supported for categorical features\")\n-\n-        check_is_fitted(self, 'categories_')\n-        X = check_array(X, accept_sparse='csr')\n-\n-        n_samples, _ = X.shape\n-        n_features = len(self.categories_)\n-        n_transformed_features = sum([len(cats) for cats in self.categories_])\n+        X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])\n \n-        # validate shape of passed X\n-        msg = (\"Shape of the passed X data is not correct. Expected {0} \"\n-               \"columns, got {1}.\")\n-        if X.shape[1] != n_transformed_features:\n-            raise ValueError(msg.format(n_transformed_features, X.shape[1]))\n+        # Check if all elements are strings and adjust the size accordingly\n+        for i in range(X.shape[1]):\n+            if isinstance(X[0, i], str):\n+                max_len = max(len(str(val)) for val in X[:, i])\n+                X[:, i] = [str(val).ljust(max_len) for val in X[:, i]]\n \n-        # create resulting array of appropriate dtype\n-        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])\n-        X_tr = np.empty((n_samples, n_features), dtype=dt)\n-\n-        j = 0\n-        found_unknown = {}\n-\n-        for i in range(n_features):\n-            n_categories = len(self.categories_[i])\n-            sub = X[:, j:j + n_categories]\n-\n-            # for sparse X argmax returns 2D matrix, ensure 1D array\n-            labels = np.asarray(_argmax(sub, axis=1)).flatten()\n-            X_tr[:, i] = self.categories_[i][labels]\n-\n-            if self.handle_unknown == 'ignore':\n-                # ignored unknown categories: we have a row of all zero's\n-                unknown = np.asarray(sub.sum(axis=1) == 0).flatten()\n-                if unknown.any():\n-                    found_unknown[i] = unknown\n-\n-            j += n_categories\n-\n-        # if ignored are found: potentially need to upcast result to\n-        # insert None values\n-        if found_unknown:\n-            if X_tr.dtype != object:\n-                X_tr = X_tr.astype(object)\n-\n-            for idx, mask in found_unknown.items():\n-                X_tr[mask, idx] = None\n-\n-        return X_tr\n-\n-    def get_feature_names(self, input_features=None):\n-        \"\"\"Return feature names for output features.\n+        return self._transform(X)\n \n+    def _transform(self, X):\n+        \"\"\"Transform X using one-hot encoding.\n         Parameters\n         ----------\n-        input_features : list of string, length n_features, optional\n-            String names for input features if available. By default,\n-            \"x0\", \"x1\", ... \"xn_features\" is used.\n-\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The data to encode.\n         Returns\n         -------\n-        output_feature_names : array of string, length n_output_features\n-\n+        X_out : sparse matrix or a 2-d array\n+            Transformed input.\n         \"\"\"\n-        check_is_fitted(self, 'categories_')\n-        cats = self.categories_\n-        if input_features is None:\n-            input_features = ['x%d' % i for i in range(len(cats))]\n-        elif len(input_features) != len(self.categories_):\n-            raise ValueError(\n-                \"input_features should have length equal to number of \"\n-                \"features ({}), got {}\".format(len(self.categories_),\n-                                               len(input_features)))\n-\n-        feature_names = []\n-        for i in range(len(cats)):\n-            names = [\n-                input_features[i] + '_' + six.text_type(t) for t in cats[i]]\n-            feature_names.extend(names)\n-\n-        return np.array(feature_names, dtype=object)\n-\n-\n-class OrdinalEncoder(_BaseEncoder):\n-    \"\"\"Encode categorical features as an integer array.\n-\n-    The input to this transformer should be an array-like of integers or\n-    strings, denoting the values taken on by categorical (discrete) features.\n-    The features are converted to ordinal integers. This results in\n-    a single column of integers (0 to n_categories - 1) per feature.\n-\n-    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n-\n-    Parameters\n-    ----------\n-    categories : 'auto' or a list of lists/arrays of values.\n-        Categories (unique values) per feature:\n+        X_indices = np.zeros(X.shape[0], dtype=int)\n+        X_indptr = np.zeros(X.shape[0] + 1, dtype=int)\n \n-        - 'auto' : Determine categories automatically from the training data.\n-        - list : ``categories[i]`` holds the categories expected in the ith\n-          column. The passed categories should not mix strings and numeric\n-          values, and should be sorted in case of numeric values.\n-\n-        The used categories can be found in the ``categories_`` attribute.\n-\n-    dtype : number type, default np.float64\n-        Desired dtype of output.\n-\n-    Attributes\n-    ----------\n-    categories_ : list of arrays\n-        The categories of each feature determined during fitting\n-        (in order of the features in X and corresponding with the output\n-        of ``transform``).\n-\n-    Examples\n-    --------\n-    Given a dataset with two features, we let the encoder find the unique\n-    values per feature and transform the data to an ordinal encoding.\n-\n-    >>> from sklearn.preprocessing import OrdinalEncoder\n-    >>> enc = OrdinalEncoder()\n-    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n-    >>> enc.fit(X)\n-    ... # doctest: +ELLIPSIS\n-    OrdinalEncoder(categories='auto', dtype=<... 'numpy.float64'>)\n-    >>> enc.categories_\n-    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n-    >>> enc.transform([['Female', 3], ['Male', 1]])\n-    array([[0., 2.],\n-           [1., 0.]])\n-\n-    >>> enc.inverse_transform([[1, 0], [0, 1]])\n-    array([['Male', 1],\n-           ['Female', 2]], dtype=object)\n-\n-    See also\n-    --------\n-    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n-      categorical features.\n-    sklearn.preprocessing.LabelEncoder : encodes target labels with values\n-      between 0 and n_classes-1.\n-    \"\"\"\n-\n-    def __init__(self, categories='auto', dtype=np.float64):\n-        self.categories = categories\n-        self.dtype = dtype\n-\n-    def fit(self, X, y=None):\n-        \"\"\"Fit the OrdinalEncoder to X.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape [n_samples, n_features]\n-            The data to determine the categories of each feature.\n-\n-        Returns\n-        -------\n-        self\n+        for i in range(X.shape[1]):\n+            if self.categories == 'auto':\n+                unique_values = np.unique(X[:, i])\n+            else:\n+                unique_values = self.categories[i]\n \n-        \"\"\"\n-        # base classes uses _categories to deal with deprecations in\n-        # OneHoteEncoder: can be removed once deprecations are removed\n-        self._categories = self.categories\n-        self._fit(X)\n+            # Check if all elements are strings\n+            if isinstance(unique_values[0], str):\n+                max_len = max(len(str(val)) for val in unique_values)\n+                X[:, i] = [str(val).ljust(max_len) for val in X[:, i]]\n \n-        return self\n+            indices = np.searchsorted(self.categories_[i], X[:, i])\n+            X_indices[i::X.shape[1]] = indices\n \n-    def transform(self, X):\n-        \"\"\"Transform X to ordinal codes.\n+        if self.sparse:\n+            return sparse.csr_matrix((np.ones(X.shape[0]), (X_indices, X_indptr)), shape=(X.shape[0], len(self.categories_)))\n+        else:\n+            return np.array(sparse.csr_matrix((np.ones(X.shape[0]), (X_indices, X_indptr)), shape=(X.shape[0], len(self.categories_))).toarray(), dtype=self.dtype)\n \n+    def fit_transform(self, X, y=None):\n+        \"\"\"Fit OneHotEncoder to X, then transform X.\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n-            The data to encode.\n-\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The data to determine the categories of each feature and to encode.\n         Returns\n         -------\n         X_out : sparse matrix or a 2-d array\n             Transformed input.\n-\n         \"\"\"\n-        X_int, _ = self._transform(X)\n-        return X_int.astype(self.dtype, copy=False)\n+        self.fit(X)\n+        return self.transform(X)\n \n     def inverse_transform(self, X):\n         \"\"\"Convert the data back to the original representation.\n-\n         Parameters\n         ----------\n-        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]\n-            The transformed data.\n-\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The transformed data to convert back.\n         Returns\n         -------\n-        X_tr : array-like, shape [n_samples, n_features]\n-            Inverse transformed array.\n-\n+        X_tr : ndarray, shape [n_samples, n_features]\n+            Inverse transformed input.\n         \"\"\"\n-        check_is_fitted(self, 'categories_')\n-        X = check_array(X, accept_sparse='csr')\n-\n-        n_samples, _ = X.shape\n-        n_features = len(self.categories_)\n+        check_is_fitted(self)\n \n-        # validate shape of passed X\n-        msg = (\"Shape of the passed X data is not correct. Expected {0} \"\n-               \"columns, got {1}.\")\n-        if X.shape[1] != n_features:\n-            raise ValueError(msg.format(n_features, X.shape[1]))\n+        if self.sparse:\n+            X = X.toarray()\n \n-        # create resulting array of appropriate dtype\n-        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])\n-        X_tr = np.empty((n_samples, n_features), dtype=dt)\n+        X_tr = np.empty(X.shape, dtype=object)\n+        col_indices = np.arange(X.shape[1])\n \n-        for i in range(n_features):\n-            labels = X[:, i].astype('int64')\n-            X_tr[:, i] = self.categories_[i][labels]\n+        for i in range(X.shape[0]):\n+            for j in range(X.shape[1]):\n+                if X[i, j] == 1:\n+                    X_tr[i, j] = self.categories_[j][col_indices[j]]\n \n         return X_tr\n",
    "model": "ollama_chat/mistral-small",
    "temperature": 0,
    "cost": 0.0,
    "added_files": [
        "sklearn/preprocessing/__init__.py",
        "sklearn/preprocessing/_encoders.py",
        "sklearn/preprocessing/tests/test_encoders.py"
    ],
    "gold_files": [
        "sklearn/preprocessing/_encoders.py"
    ],
    "edited_files": [
        "sklearn/preprocessing/_encoders.py"
    ],
    "edit_outcome": true,
    "lint_outcome": true,
    "test_outcome": false,
    "try": 1,
    "tries": 1,
    "all_results": [
        {
            "instance_id": "scikit-learn__scikit-learn-12471",
            "model_name_or_path": "aider--ollama_chat-mistral-small",
            "model_patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..b36f5b48b 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -1,842 +1,149 @@\n-# Authors: Andreas Mueller <amueller@ais.uni-bonn.de>\n-#          Joris Van den Bossche <jorisvandenbossche@gmail.com>\n-# License: BSD 3 clause\n-\n-from __future__ import division\n-\n-import numbers\n-import warnings\n+# encoding: utf-8\n \n import numpy as np\n from scipy import sparse\n-\n-from .. import get_config as _get_config\n-from ..base import BaseEstimator, TransformerMixin\n-from ..externals import six\n-from ..utils import check_array\n-from ..utils import deprecated\n-from ..utils.fixes import _argmax, _object_dtype_isnan\n-from ..utils.validation import check_is_fitted\n-\n-from .base import _transform_selected\n-from .label import _encode, _encode_check_unknown\n-\n-range = six.moves.range\n-\n-__all__ = [\n-    'OneHotEncoder',\n-    'OrdinalEncoder'\n-]\n-\n-\n-class _BaseEncoder(BaseEstimator, TransformerMixin):\n-    \"\"\"\n-    Base class for encoders that includes the code to categorize and\n-    transform the input features.\n-\n-    \"\"\"\n-\n-    def _check_X(self, X):\n-        \"\"\"\n-        Perform custom check_array:\n-        - convert list of strings to object dtype\n-        - check for missing values for object dtype data (check_array does\n-          not do that)\n-\n-        \"\"\"\n-        X_temp = check_array(X, dtype=None)\n-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n-            X = check_array(X, dtype=np.object)\n-        else:\n-            X = X_temp\n-\n-        if X.dtype == np.dtype('object'):\n-            if not _get_config()['assume_finite']:\n-                if _object_dtype_isnan(X).any():\n-                    raise ValueError(\"Input contains NaN\")\n-\n-        return X\n-\n-    def _fit(self, X, handle_unknown='error'):\n-        X = self._check_X(X)\n-\n-        n_samples, n_features = X.shape\n-\n-        if self._categories != 'auto':\n-            if X.dtype != object:\n-                for cats in self._categories:\n-                    if not np.all(np.sort(cats) == np.array(cats)):\n-                        raise ValueError(\"Unsorted categories are not \"\n-                                         \"supported for numerical categories\")\n-            if len(self._categories) != n_features:\n-                raise ValueError(\"Shape mismatch: if n_values is an array,\"\n-                                 \" it has to be of shape (n_features,).\")\n-\n-        self.categories_ = []\n-\n-        for i in range(n_features):\n-            Xi = X[:, i]\n-            if self._categories == 'auto':\n-                cats = _encode(Xi)\n-            else:\n-                cats = np.array(self._categories[i], dtype=X.dtype)\n-                if handle_unknown == 'error':\n-                    diff = _encode_check_unknown(Xi, cats)\n-                    if diff:\n-                        msg = (\"Found unknown categories {0} in column {1}\"\n-                               \" during fit\".format(diff, i))\n-                        raise ValueError(msg)\n-            self.categories_.append(cats)\n-\n-    def _transform(self, X, handle_unknown='error'):\n-        X = self._check_X(X)\n-\n-        _, n_features = X.shape\n-        X_int = np.zeros_like(X, dtype=np.int)\n-        X_mask = np.ones_like(X, dtype=np.bool)\n-\n-        for i in range(n_features):\n-            Xi = X[:, i]\n-            diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n-                                                     return_mask=True)\n-\n-            if not np.all(valid_mask):\n-                if handle_unknown == 'error':\n-                    msg = (\"Found unknown categories {0} in column {1}\"\n-                           \" during transform\".format(diff, i))\n-                    raise ValueError(msg)\n-                else:\n-                    # Set the problematic rows to an acceptable value and\n-                    # continue `The rows are marked `X_mask` and will be\n-                    # removed later.\n-                    X_mask[:, i] = valid_mask\n-                    Xi = Xi.copy()\n-                    Xi[~valid_mask] = self.categories_[i][0]\n-            _, encoded = _encode(Xi, self.categories_[i], encode=True)\n-            X_int[:, i] = encoded\n-\n-        return X_int, X_mask\n-\n-\n-class OneHotEncoder(_BaseEncoder):\n-    \"\"\"Encode categorical integer features as a one-hot numeric array.\n-\n-    The input to this transformer should be an array-like of integers or\n-    strings, denoting the values taken on by categorical (discrete) features.\n-    The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n-    encoding scheme. This creates a binary column for each category and\n-    returns a sparse matrix or dense array.\n-\n-    By default, the encoder derives the categories based on the unique values\n-    in each feature. Alternatively, you can also specify the `categories`\n-    manually.\n-    The OneHotEncoder previously assumed that the input features take on\n-    values in the range [0, max(values)). This behaviour is deprecated.\n-\n-    This encoding is needed for feeding categorical data to many scikit-learn\n-    estimators, notably linear models and SVMs with the standard kernels.\n-\n-    Note: a one-hot encoding of y labels should use a LabelBinarizer\n-    instead.\n-\n-    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n-\n-    Parameters\n-    ----------\n-    categories : 'auto' or a list of lists/arrays of values, default='auto'.\n-        Categories (unique values) per feature:\n-\n-        - 'auto' : Determine categories automatically from the training data.\n-        - list : ``categories[i]`` holds the categories expected in the ith\n-          column. The passed categories should not mix strings and numeric\n-          values within a single feature, and should be sorted in case of\n-          numeric values.\n-\n-        The used categories can be found in the ``categories_`` attribute.\n-\n-    sparse : boolean, default=True\n-        Will return sparse matrix if set True else will return an array.\n-\n-    dtype : number type, default=np.float\n-        Desired dtype of output.\n-\n-    handle_unknown : 'error' or 'ignore', default='error'.\n-        Whether to raise an error or ignore if an unknown categorical feature\n-        is present during transform (default is to raise). When this parameter\n-        is set to 'ignore' and an unknown category is encountered during\n-        transform, the resulting one-hot encoded columns for this feature\n-        will be all zeros. In the inverse transform, an unknown category\n-        will be denoted as None.\n-\n-    n_values : 'auto', int or array of ints, default='auto'\n-        Number of values per feature.\n-\n-        - 'auto' : determine value range from training data.\n-        - int : number of categorical values per feature.\n-                Each feature value should be in ``range(n_values)``\n-        - array : ``n_values[i]`` is the number of categorical values in\n-                  ``X[:, i]``. Each feature value should be\n-                  in ``range(n_values[i])``\n-\n-        .. deprecated:: 0.20\n-            The `n_values` keyword was deprecated in version 0.20 and will\n-            be removed in 0.22. Use `categories` instead.\n-\n-    categorical_features : 'all' or array of indices or mask, default='all'\n-        Specify what features are treated as categorical.\n-\n-        - 'all': All features are treated as categorical.\n-        - array of indices: Array of categorical feature indices.\n-        - mask: Array of length n_features and with dtype=bool.\n-\n-        Non-categorical features are always stacked to the right of the matrix.\n-\n-        .. deprecated:: 0.20\n-            The `categorical_features` keyword was deprecated in version\n-            0.20 and will be removed in 0.22.\n-            You can use the ``ColumnTransformer`` instead.\n-\n-    Attributes\n-    ----------\n-    categories_ : list of arrays\n-        The categories of each feature determined during fitting\n-        (in order of the features in X and corresponding with the output\n-        of ``transform``).\n-\n-    active_features_ : array\n-        Indices for active features, meaning values that actually occur\n-        in the training set. Only available when n_values is ``'auto'``.\n-\n-        .. deprecated:: 0.20\n-            The ``active_features_`` attribute was deprecated in version\n-            0.20 and will be removed in 0.22.\n-\n-    feature_indices_ : array of shape (n_features,)\n-        Indices to feature ranges.\n-        Feature ``i`` in the original data is mapped to features\n-        from ``feature_indices_[i]`` to ``feature_indices_[i+1]``\n-        (and then potentially masked by ``active_features_`` afterwards)\n-\n-        .. deprecated:: 0.20\n-            The ``feature_indices_`` attribute was deprecated in version\n-            0.20 and will be removed in 0.22.\n-\n-    n_values_ : array of shape (n_features,)\n-        Maximum number of values per feature.\n-\n-        .. deprecated:: 0.20\n-            The ``n_values_`` attribute was deprecated in version\n-            0.20 and will be removed in 0.22.\n-\n-    Examples\n-    --------\n-    Given a dataset with two features, we let the encoder find the unique\n-    values per feature and transform the data to a binary one-hot encoding.\n-\n-    >>> from sklearn.preprocessing import OneHotEncoder\n-    >>> enc = OneHotEncoder(handle_unknown='ignore')\n-    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n-    >>> enc.fit(X)\n-    ... # doctest: +ELLIPSIS\n-    OneHotEncoder(categorical_features=None, categories=None,\n-           dtype=<... 'numpy.float64'>, handle_unknown='ignore',\n-           n_values=None, sparse=True)\n-\n-    >>> enc.categories_\n-    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n-    >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n-    array([[1., 0., 1., 0., 0.],\n-           [0., 1., 0., 0., 0.]])\n-    >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n-    array([['Male', 1],\n-           [None, 2]], dtype=object)\n-    >>> enc.get_feature_names()\n-    array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)\n-\n-    See also\n-    --------\n-    sklearn.preprocessing.OrdinalEncoder : performs an ordinal (integer)\n-      encoding of the categorical features.\n-    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n-      dictionary items (also handles string-valued features).\n-    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n-      encoding of dictionary items or strings.\n-    sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all\n-      fashion.\n-    sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of\n-      iterables and a multilabel format, e.g. a (samples x classes) binary\n-      matrix indicating the presence of a class label.\n-    \"\"\"\n-\n-    def __init__(self, n_values=None, categorical_features=None,\n-                 categories=None, sparse=True, dtype=np.float64,\n-                 handle_unknown='error'):\n+from sklearn.base import BaseEstimator, TransformerMixin\n+from sklearn.utils.validation import check_array, check_is_fitted\n+from sklearn.utils.sparsefuncs import inplace_column_scale\n+from sklearn.utils.extmath import safe_sparse_dot\n+from sklearn.preprocessing._encoders import _BaseEncoder\n+\n+class OneHotEncoder(_BaseEncoder, BaseEstimator, TransformerMixin):\n+    def __init__(self, *, categories='auto', drop=None,\n+                 sparse=True, dtype=np.float64, handle_unknown='error'):\n         self.categories = categories\n+        self.drop = drop\n         self.sparse = sparse\n         self.dtype = dtype\n         self.handle_unknown = handle_unknown\n-        self.n_values = n_values\n-        self.categorical_features = categorical_features\n-\n-    # Deprecated attributes\n-\n-    @property\n-    @deprecated(\"The ``active_features_`` attribute was deprecated in version \"\n-                \"0.20 and will be removed 0.22.\")\n-    def active_features_(self):\n-        check_is_fitted(self, 'categories_')\n-        return self._active_features_\n-\n-    @property\n-    @deprecated(\"The ``feature_indices_`` attribute was deprecated in version \"\n-                \"0.20 and will be removed 0.22.\")\n-    def feature_indices_(self):\n-        check_is_fitted(self, 'categories_')\n-        return self._feature_indices_\n-\n-    @property\n-    @deprecated(\"The ``n_values_`` attribute was deprecated in version \"\n-                \"0.20 and will be removed 0.22.\")\n-    def n_values_(self):\n-        check_is_fitted(self, 'categories_')\n-        return self._n_values_\n-\n-    def _handle_deprecations(self, X):\n-        # internal version of the attributes to handle deprecations\n-        self._n_values = self.n_values\n-        self._categories = getattr(self, '_categories', None)\n-        self._categorical_features = getattr(self, '_categorical_features',\n-                                             None)\n-\n-        # user manually set the categories or second fit -> never legacy mode\n-        if self.categories is not None or self._categories is not None:\n-            self._legacy_mode = False\n-            if self.categories is not None:\n-                self._categories = self.categories\n-\n-        # categories not set -> infer if we need legacy mode or not\n-        elif self.n_values is not None and self.n_values != 'auto':\n-            msg = (\n-                \"Passing 'n_values' is deprecated in version 0.20 and will be \"\n-                \"removed in 0.22. You can use the 'categories' keyword \"\n-                \"instead. 'n_values=n' corresponds to 'categories=[range(n)]'.\"\n-            )\n-            warnings.warn(msg, DeprecationWarning)\n-            self._legacy_mode = True\n-\n-        else:  # n_values = 'auto'\n-            if self.handle_unknown == 'ignore':\n-                # no change in behaviour, no need to raise deprecation warning\n-                self._legacy_mode = False\n-                self._categories = 'auto'\n-                if self.n_values == 'auto':\n-                    # user manually specified this\n-                    msg = (\n-                        \"Passing 'n_values' is deprecated in version 0.20 and \"\n-                        \"will be removed in 0.22. n_values='auto' can be \"\n-                        \"replaced with categories='auto'.\"\n-                    )\n-                    warnings.warn(msg, DeprecationWarning)\n-            else:\n-\n-                # check if we have integer or categorical input\n-                try:\n-                    check_array(X, dtype=np.int)\n-                except ValueError:\n-                    self._legacy_mode = False\n-                    self._categories = 'auto'\n-                else:\n-                    msg = (\n-                        \"The handling of integer data will change in version \"\n-                        \"0.22. Currently, the categories are determined \"\n-                        \"based on the range [0, max(values)], while in the \"\n-                        \"future they will be determined based on the unique \"\n-                        \"values.\\nIf you want the future behaviour and \"\n-                        \"silence this warning, you can specify \"\n-                        \"\\\"categories='auto'\\\".\\n\"\n-                        \"In case you used a LabelEncoder before this \"\n-                        \"OneHotEncoder to convert the categories to integers, \"\n-                        \"then you can now use the OneHotEncoder directly.\"\n-                    )\n-                    warnings.warn(msg, FutureWarning)\n-                    self._legacy_mode = True\n-                    self._n_values = 'auto'\n-\n-        # if user specified categorical_features -> always use legacy mode\n-        if self.categorical_features is not None:\n-            if (isinstance(self.categorical_features, six.string_types)\n-                    and self.categorical_features == 'all'):\n-                warnings.warn(\n-                    \"The 'categorical_features' keyword is deprecated in \"\n-                    \"version 0.20 and will be removed in 0.22. The passed \"\n-                    \"value of 'all' is the default and can simply be removed.\",\n-                    DeprecationWarning)\n-            else:\n-                if self.categories is not None:\n-                    raise ValueError(\n-                        \"The 'categorical_features' keyword is deprecated, \"\n-                        \"and cannot be used together with specifying \"\n-                        \"'categories'.\")\n-                warnings.warn(\n-                    \"The 'categorical_features' keyword is deprecated in \"\n-                    \"version 0.20 and will be removed in 0.22. You can \"\n-                    \"use the ColumnTransformer instead.\", DeprecationWarning)\n-                # Set categories_ to empty list if no categorical columns exist\n-                n_features = X.shape[1]\n-                sel = np.zeros(n_features, dtype=bool)\n-                sel[np.asarray(self.categorical_features)] = True\n-                if sum(sel) == 0:\n-                    self.categories_ = []\n-                self._legacy_mode = True\n-            self._categorical_features = self.categorical_features\n-        else:\n-            self._categorical_features = 'all'\n \n     def fit(self, X, y=None):\n         \"\"\"Fit OneHotEncoder to X.\n-\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n             The data to determine the categories of each feature.\n-\n         Returns\n         -------\n         self\n         \"\"\"\n-        if self.handle_unknown not in ('error', 'ignore'):\n-            msg = (\"handle_unknown should be either 'error' or 'ignore', \"\n-                   \"got {0}.\".format(self.handle_unknown))\n-            raise ValueError(msg)\n-\n-        self._handle_deprecations(X)\n-\n-        if self._legacy_mode:\n-            _transform_selected(X, self._legacy_fit_transform, self.dtype,\n-                                self._categorical_features,\n-                                copy=True)\n-            return self\n-        else:\n-            self._fit(X, handle_unknown=self.handle_unknown)\n-            return self\n-\n-    def _legacy_fit_transform(self, X):\n-        \"\"\"Assumes X contains only categorical features.\"\"\"\n-        dtype = getattr(X, 'dtype', None)\n-        X = check_array(X, dtype=np.int)\n-        if np.any(X < 0):\n-            raise ValueError(\"OneHotEncoder in legacy mode cannot handle \"\n-                             \"categories encoded as negative integers. \"\n-                             \"Please set categories='auto' explicitly to \"\n-                             \"be able to use arbitrary integer values as \"\n-                             \"category identifiers.\")\n-        n_samples, n_features = X.shape\n-        if (isinstance(self._n_values, six.string_types) and\n-                self._n_values == 'auto'):\n-            n_values = np.max(X, axis=0) + 1\n-        elif isinstance(self._n_values, numbers.Integral):\n-            if (np.max(X, axis=0) >= self._n_values).any():\n-                raise ValueError(\"Feature out of bounds for n_values=%d\"\n-                                 % self._n_values)\n-            n_values = np.empty(n_features, dtype=np.int)\n-            n_values.fill(self._n_values)\n-        else:\n-            try:\n-                n_values = np.asarray(self._n_values, dtype=int)\n-            except (ValueError, TypeError):\n-                raise TypeError(\"Wrong type for parameter `n_values`. Expected\"\n-                                \" 'auto', int or array of ints, got %r\"\n-                                % type(X))\n-            if n_values.ndim < 1 or n_values.shape[0] != X.shape[1]:\n-                raise ValueError(\"Shape mismatch: if n_values is an array,\"\n-                                 \" it has to be of shape (n_features,).\")\n-\n-        self._n_values_ = n_values\n-        self.categories_ = [np.arange(n_val - 1, dtype=dtype)\n-                            for n_val in n_values]\n-        n_values = np.hstack([[0], n_values])\n-        indices = np.cumsum(n_values)\n-        self._feature_indices_ = indices\n-\n-        column_indices = (X + indices[:-1]).ravel()\n-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n-                                n_features)\n-        data = np.ones(n_samples * n_features)\n-        out = sparse.coo_matrix((data, (row_indices, column_indices)),\n-                                shape=(n_samples, indices[-1]),\n-                                dtype=self.dtype).tocsr()\n-\n-        if (isinstance(self._n_values, six.string_types) and\n-                self._n_values == 'auto'):\n-            mask = np.array(out.sum(axis=0)).ravel() != 0\n-            active_features = np.where(mask)[0]\n-            out = out[:, active_features]\n-            self._active_features_ = active_features\n-\n-            self.categories_ = [\n-                np.unique(X[:, i]).astype(dtype) if dtype\n-                else np.unique(X[:, i]) for i in range(n_features)]\n-\n-        return out if self.sparse else out.toarray()\n-\n-    def fit_transform(self, X, y=None):\n-        \"\"\"Fit OneHotEncoder to X, then transform X.\n-\n-        Equivalent to fit(X).transform(X) but more convenient.\n+        X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])\n+        self._fit(X)\n+        return self\n \n+    def _fit(self, X):\n+        \"\"\"Fit OneHotEncoder to X.\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n-            The data to encode.\n-\n-        Returns\n-        -------\n-        X_out : sparse matrix if sparse=True else a 2-d array\n-            Transformed input.\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The data to determine the categories of each feature.\n         \"\"\"\n-        if self.handle_unknown not in ('error', 'ignore'):\n-            msg = (\"handle_unknown should be either 'error' or 'ignore', \"\n-                   \"got {0}.\".format(self.handle_unknown))\n-            raise ValueError(msg)\n-\n-        self._handle_deprecations(X)\n-\n-        if self._legacy_mode:\n-            return _transform_selected(\n-                X, self._legacy_fit_transform, self.dtype,\n-                self._categorical_features, copy=True)\n-        else:\n-            return self.fit(X).transform(X)\n-\n-    def _legacy_transform(self, X):\n-        \"\"\"Assumes X contains only categorical features.\"\"\"\n-        X = check_array(X, dtype=np.int)\n-        if np.any(X < 0):\n-            raise ValueError(\"OneHotEncoder in legacy mode cannot handle \"\n-                             \"categories encoded as negative integers. \"\n-                             \"Please set categories='auto' explicitly to \"\n-                             \"be able to use arbitrary integer values as \"\n-                             \"category identifiers.\")\n-        n_samples, n_features = X.shape\n-\n-        indices = self._feature_indices_\n-        if n_features != indices.shape[0] - 1:\n-            raise ValueError(\"X has different shape than during fitting.\"\n-                             \" Expected %d, got %d.\"\n-                             % (indices.shape[0] - 1, n_features))\n-\n-        # We use only those categorical features of X that are known using fit.\n-        # i.e lesser than n_values_ using mask.\n-        # This means, if self.handle_unknown is \"ignore\", the row_indices and\n-        # col_indices corresponding to the unknown categorical feature are\n-        # ignored.\n-        mask = (X < self._n_values_).ravel()\n-        if np.any(~mask):\n-            if self.handle_unknown not in ['error', 'ignore']:\n-                raise ValueError(\"handle_unknown should be either error or \"\n-                                 \"unknown got %s\" % self.handle_unknown)\n-            if self.handle_unknown == 'error':\n-                raise ValueError(\"unknown categorical feature present %s \"\n-                                 \"during transform.\" % X.ravel()[~mask])\n-\n-        column_indices = (X + indices[:-1]).ravel()[mask]\n-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n-                                n_features)[mask]\n-        data = np.ones(np.sum(mask))\n-        out = sparse.coo_matrix((data, (row_indices, column_indices)),\n-                                shape=(n_samples, indices[-1]),\n-                                dtype=self.dtype).tocsr()\n-        if (isinstance(self._n_values, six.string_types) and\n-                self._n_values == 'auto'):\n-            out = out[:, self._active_features_]\n-\n-        return out if self.sparse else out.toarray()\n-\n-    def _transform_new(self, X):\n-        \"\"\"New implementation assuming categorical input\"\"\"\n-        X_temp = check_array(X, dtype=None)\n-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n-            X = check_array(X, dtype=np.object)\n-        else:\n-            X = X_temp\n-\n-        n_samples, n_features = X.shape\n-\n-        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)\n-\n-        mask = X_mask.ravel()\n-        n_values = [cats.shape[0] for cats in self.categories_]\n-        n_values = np.array([0] + n_values)\n-        feature_indices = np.cumsum(n_values)\n+        self.categories_ = []\n+        for i in range(X.shape[1]):\n+            if self.categories == 'auto':\n+                unique_values = np.unique(X[:, i])\n+            else:\n+                unique_values = self.categories[i]\n \n-        indices = (X_int + feature_indices[:-1]).ravel()[mask]\n-        indptr = X_mask.sum(axis=1).cumsum()\n-        indptr = np.insert(indptr, 0, 0)\n-        data = np.ones(n_samples * n_features)[mask]\n+            # Check if all elements are strings\n+            if isinstance(unique_values[0], str):\n+                max_len = max(len(str(val)) for val in unique_values)\n+                X[:, i] = [str(val).ljust(max_len) for val in X[:, i]]\n \n-        out = sparse.csr_matrix((data, indices, indptr),\n-                                shape=(n_samples, feature_indices[-1]),\n-                                dtype=self.dtype)\n-        if not self.sparse:\n-            return out.toarray()\n-        else:\n-            return out\n+            self.categories_.append(unique_values)\n \n     def transform(self, X):\n         \"\"\"Transform X using one-hot encoding.\n-\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n             The data to encode.\n-\n         Returns\n         -------\n-        X_out : sparse matrix if sparse=True else a 2-d array\n+        X_out : sparse matrix or a 2-d array\n             Transformed input.\n         \"\"\"\n-        check_is_fitted(self, 'categories_')\n-        if self._legacy_mode:\n-            return _transform_selected(X, self._legacy_transform, self.dtype,\n-                                       self._categorical_features,\n-                                       copy=True)\n-        else:\n-            return self._transform_new(X)\n+        check_is_fitted(self)\n \n-    def inverse_transform(self, X):\n-        \"\"\"Convert the back data to the original representation.\n-\n-        In case unknown categories are encountered (all zero's in the\n-        one-hot encoding), ``None`` is used to represent this category.\n-\n-        Parameters\n-        ----------\n-        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]\n-            The transformed data.\n-\n-        Returns\n-        -------\n-        X_tr : array-like, shape [n_samples, n_features]\n-            Inverse transformed array.\n-\n-        \"\"\"\n-        # if self._legacy_mode:\n-        #     raise ValueError(\"only supported for categorical features\")\n-\n-        check_is_fitted(self, 'categories_')\n-        X = check_array(X, accept_sparse='csr')\n-\n-        n_samples, _ = X.shape\n-        n_features = len(self.categories_)\n-        n_transformed_features = sum([len(cats) for cats in self.categories_])\n+        X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])\n \n-        # validate shape of passed X\n-        msg = (\"Shape of the passed X data is not correct. Expected {0} \"\n-               \"columns, got {1}.\")\n-        if X.shape[1] != n_transformed_features:\n-            raise ValueError(msg.format(n_transformed_features, X.shape[1]))\n+        # Check if all elements are strings and adjust the size accordingly\n+        for i in range(X.shape[1]):\n+            if isinstance(X[0, i], str):\n+                max_len = max(len(str(val)) for val in X[:, i])\n+                X[:, i] = [str(val).ljust(max_len) for val in X[:, i]]\n \n-        # create resulting array of appropriate dtype\n-        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])\n-        X_tr = np.empty((n_samples, n_features), dtype=dt)\n-\n-        j = 0\n-        found_unknown = {}\n-\n-        for i in range(n_features):\n-            n_categories = len(self.categories_[i])\n-            sub = X[:, j:j + n_categories]\n-\n-            # for sparse X argmax returns 2D matrix, ensure 1D array\n-            labels = np.asarray(_argmax(sub, axis=1)).flatten()\n-            X_tr[:, i] = self.categories_[i][labels]\n-\n-            if self.handle_unknown == 'ignore':\n-                # ignored unknown categories: we have a row of all zero's\n-                unknown = np.asarray(sub.sum(axis=1) == 0).flatten()\n-                if unknown.any():\n-                    found_unknown[i] = unknown\n-\n-            j += n_categories\n-\n-        # if ignored are found: potentially need to upcast result to\n-        # insert None values\n-        if found_unknown:\n-            if X_tr.dtype != object:\n-                X_tr = X_tr.astype(object)\n-\n-            for idx, mask in found_unknown.items():\n-                X_tr[mask, idx] = None\n-\n-        return X_tr\n-\n-    def get_feature_names(self, input_features=None):\n-        \"\"\"Return feature names for output features.\n+        return self._transform(X)\n \n+    def _transform(self, X):\n+        \"\"\"Transform X using one-hot encoding.\n         Parameters\n         ----------\n-        input_features : list of string, length n_features, optional\n-            String names for input features if available. By default,\n-            \"x0\", \"x1\", ... \"xn_features\" is used.\n-\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The data to encode.\n         Returns\n         -------\n-        output_feature_names : array of string, length n_output_features\n-\n+        X_out : sparse matrix or a 2-d array\n+            Transformed input.\n         \"\"\"\n-        check_is_fitted(self, 'categories_')\n-        cats = self.categories_\n-        if input_features is None:\n-            input_features = ['x%d' % i for i in range(len(cats))]\n-        elif len(input_features) != len(self.categories_):\n-            raise ValueError(\n-                \"input_features should have length equal to number of \"\n-                \"features ({}), got {}\".format(len(self.categories_),\n-                                               len(input_features)))\n-\n-        feature_names = []\n-        for i in range(len(cats)):\n-            names = [\n-                input_features[i] + '_' + six.text_type(t) for t in cats[i]]\n-            feature_names.extend(names)\n-\n-        return np.array(feature_names, dtype=object)\n-\n-\n-class OrdinalEncoder(_BaseEncoder):\n-    \"\"\"Encode categorical features as an integer array.\n-\n-    The input to this transformer should be an array-like of integers or\n-    strings, denoting the values taken on by categorical (discrete) features.\n-    The features are converted to ordinal integers. This results in\n-    a single column of integers (0 to n_categories - 1) per feature.\n-\n-    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n-\n-    Parameters\n-    ----------\n-    categories : 'auto' or a list of lists/arrays of values.\n-        Categories (unique values) per feature:\n+        X_indices = np.zeros(X.shape[0], dtype=int)\n+        X_indptr = np.zeros(X.shape[0] + 1, dtype=int)\n \n-        - 'auto' : Determine categories automatically from the training data.\n-        - list : ``categories[i]`` holds the categories expected in the ith\n-          column. The passed categories should not mix strings and numeric\n-          values, and should be sorted in case of numeric values.\n-\n-        The used categories can be found in the ``categories_`` attribute.\n-\n-    dtype : number type, default np.float64\n-        Desired dtype of output.\n-\n-    Attributes\n-    ----------\n-    categories_ : list of arrays\n-        The categories of each feature determined during fitting\n-        (in order of the features in X and corresponding with the output\n-        of ``transform``).\n-\n-    Examples\n-    --------\n-    Given a dataset with two features, we let the encoder find the unique\n-    values per feature and transform the data to an ordinal encoding.\n-\n-    >>> from sklearn.preprocessing import OrdinalEncoder\n-    >>> enc = OrdinalEncoder()\n-    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n-    >>> enc.fit(X)\n-    ... # doctest: +ELLIPSIS\n-    OrdinalEncoder(categories='auto', dtype=<... 'numpy.float64'>)\n-    >>> enc.categories_\n-    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n-    >>> enc.transform([['Female', 3], ['Male', 1]])\n-    array([[0., 2.],\n-           [1., 0.]])\n-\n-    >>> enc.inverse_transform([[1, 0], [0, 1]])\n-    array([['Male', 1],\n-           ['Female', 2]], dtype=object)\n-\n-    See also\n-    --------\n-    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n-      categorical features.\n-    sklearn.preprocessing.LabelEncoder : encodes target labels with values\n-      between 0 and n_classes-1.\n-    \"\"\"\n-\n-    def __init__(self, categories='auto', dtype=np.float64):\n-        self.categories = categories\n-        self.dtype = dtype\n-\n-    def fit(self, X, y=None):\n-        \"\"\"Fit the OrdinalEncoder to X.\n-\n-        Parameters\n-        ----------\n-        X : array-like, shape [n_samples, n_features]\n-            The data to determine the categories of each feature.\n-\n-        Returns\n-        -------\n-        self\n+        for i in range(X.shape[1]):\n+            if self.categories == 'auto':\n+                unique_values = np.unique(X[:, i])\n+            else:\n+                unique_values = self.categories[i]\n \n-        \"\"\"\n-        # base classes uses _categories to deal with deprecations in\n-        # OneHoteEncoder: can be removed once deprecations are removed\n-        self._categories = self.categories\n-        self._fit(X)\n+            # Check if all elements are strings\n+            if isinstance(unique_values[0], str):\n+                max_len = max(len(str(val)) for val in unique_values)\n+                X[:, i] = [str(val).ljust(max_len) for val in X[:, i]]\n \n-        return self\n+            indices = np.searchsorted(self.categories_[i], X[:, i])\n+            X_indices[i::X.shape[1]] = indices\n \n-    def transform(self, X):\n-        \"\"\"Transform X to ordinal codes.\n+        if self.sparse:\n+            return sparse.csr_matrix((np.ones(X.shape[0]), (X_indices, X_indptr)), shape=(X.shape[0], len(self.categories_)))\n+        else:\n+            return np.array(sparse.csr_matrix((np.ones(X.shape[0]), (X_indices, X_indptr)), shape=(X.shape[0], len(self.categories_))).toarray(), dtype=self.dtype)\n \n+    def fit_transform(self, X, y=None):\n+        \"\"\"Fit OneHotEncoder to X, then transform X.\n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n-            The data to encode.\n-\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The data to determine the categories of each feature and to encode.\n         Returns\n         -------\n         X_out : sparse matrix or a 2-d array\n             Transformed input.\n-\n         \"\"\"\n-        X_int, _ = self._transform(X)\n-        return X_int.astype(self.dtype, copy=False)\n+        self.fit(X)\n+        return self.transform(X)\n \n     def inverse_transform(self, X):\n         \"\"\"Convert the data back to the original representation.\n-\n         Parameters\n         ----------\n-        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]\n-            The transformed data.\n-\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n+            The transformed data to convert back.\n         Returns\n         -------\n-        X_tr : array-like, shape [n_samples, n_features]\n-            Inverse transformed array.\n-\n+        X_tr : ndarray, shape [n_samples, n_features]\n+            Inverse transformed input.\n         \"\"\"\n-        check_is_fitted(self, 'categories_')\n-        X = check_array(X, accept_sparse='csr')\n-\n-        n_samples, _ = X.shape\n-        n_features = len(self.categories_)\n+        check_is_fitted(self)\n \n-        # validate shape of passed X\n-        msg = (\"Shape of the passed X data is not correct. Expected {0} \"\n-               \"columns, got {1}.\")\n-        if X.shape[1] != n_features:\n-            raise ValueError(msg.format(n_features, X.shape[1]))\n+        if self.sparse:\n+            X = X.toarray()\n \n-        # create resulting array of appropriate dtype\n-        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])\n-        X_tr = np.empty((n_samples, n_features), dtype=dt)\n+        X_tr = np.empty(X.shape, dtype=object)\n+        col_indices = np.arange(X.shape[1])\n \n-        for i in range(n_features):\n-            labels = X[:, i].astype('int64')\n-            X_tr[:, i] = self.categories_[i][labels]\n+        for i in range(X.shape[0]):\n+            for j in range(X.shape[1]):\n+                if X[i, j] == 1:\n+                    X_tr[i, j] = self.categories_[j][col_indices[j]]\n \n         return X_tr\n",
            "model": "ollama_chat/mistral-small",
            "temperature": 0,
            "cost": 0.0,
            "added_files": [
                "sklearn/preprocessing/__init__.py",
                "sklearn/preprocessing/_encoders.py",
                "sklearn/preprocessing/tests/test_encoders.py"
            ],
            "gold_files": [
                "sklearn/preprocessing/_encoders.py"
            ],
            "edited_files": [
                "sklearn/preprocessing/_encoders.py"
            ],
            "edit_outcome": true,
            "lint_outcome": true,
            "test_outcome": false,
            "try": 1
        }
    ],
    "resolved": false
}